我們也透過我們這個AI的這個開發套件，用在這些相關的領域上面，去支持整個的客戶的這些Logic的應用。那這裡面有加速卡，有GPU有CPU，各式各樣的組合。那我們除了透過之前Intel的OpenVINO這樣的一個Framework以外，我們也加上了像DIPX或是這一類的Hilo這一類的加速的Framework。那這部分呢，主要是讓我們的系統整合商的客戶，他就可以很容易的去往下去進展，但是事實上，這個落體通常就要比較多的時間。所以呢，有鑒於使我們從一開始的Develop Kit，我們開始往下去，聚焦這幾個方向，然後去開發我們的所謂Penny Solution，一個就是剛剛講的Edge到雲端的方向，就是這種協同的方式，那就是支援整個LM跟SM本地化，SLM本地化的這個邊緣伺服器，這個代號我們叫做Gaia，Gaia AI這個系列。那這一部分的話，我們上面可以讓各種輕量化的這個模型，那同時呢，我們可以在非常非常低的這種所謂的CPP，就是功耗下面，我們依然可以運作這個7B的這種參數的模型。

那另外呢，模組化設計，像剛剛提到Hydro跟DX這一類的AI模塊，那跟我們更大的GP，我們都可以在上面去加以運作。然後另外呢，很重要的，我們在歐洲，特別在歐洲這一陣子，我們面對到很多的資安的要求，因為這個東西，我們做了一個整個，而不是只有傳統硬體，包括我們的收費上去，聯合給上去的時候，實際對於資安的要求，他們也開始去要求我們去加強這方面的一些開發。所以這幾件包括這種Gerotrust，或是整合這些安全晶片，甚至包括我們現在有新防抵的這個Security，那還有另外就是Base-2還有另外是RCA，歐洲RCA這些，然後GRI這些的規範。那另外就是整個溯源，從我們原本的這些原物料到一路到我們這上面的收費，那另外呢，我們自己也開發我們自己的收費，去做這種高可用度，高可用度的多節點，分散式的運算。然後同時，跟我們的子公司QNAP，我們也同時去建立這種資安上面的通訪的這個演練，罰場，那強調是讓我們整個空地，可能邊緣這邊的資安，要獲得一定程度的確保。好，那這個部分是，我們一個應用，我們已經下設起來，就是說這裡面所有的東西，除了上面的NAS，是用的是QNAP，其他都是我們的系統，去兜起來的一個整合的應用。

我們在中間，核心做大圓模型這邊的話，用的是一種Gaia Server，那Gaia Server，這邊我們也特意讓它，不一定是一個RECMAR，而是一個桌上型的，但是它有足夠的深度，可以擺放全高全長，雙槽寬的這個GPU卡。那當然它不插GPU卡，沒關係，它一定程度的GPU上的順利。那另外呢，在前端就是我們的TANK，TANK系列是負責資料蒐集，那這裡面呢，我們上面用跑的所謂的SLM，所以這一部分就是前端很快速的反應，針對這些Sensor，針對這些Camera，針對來自相關感測器的，它快速的去反應，要執行這上面的SLM，然後去讓前端的人，可以很快速的互動，去設定，然後去反應。但是呢，最終當我們先知道ERP，MES，CRM，JL大系統的時候，它就會回到我們Gaia Server，做這種LRM，這方面的多語言，多系統中間的資料的會議整個分析。那最終呈現在我們最左邊，我們的Panel PD，上面是我們人機介面，那資料呢，就存在我們的，那個，它那個QMAP的這個NAS。所以這整個生態系統，實際上已經把它串起來， 而且在上面有各式各樣的應用，開始在上面開放。

另外一個這個是我們現在自己，也自己開發一個，資安偵測開放置名台，這個為什麼叫做開放置名台，因為我們也，這次上面，同時運用了這種GI的這種檢測，去檢測說你有沒有戴安全帽，有沒有穿安全背心，甚至有沒有穿，不敢穿過不敢穿過的門。那這上面呢，過往要設定這些條件，實際上很痛苦，然後幾乎是要寫成是，我們現在就把SOM大字拿來，我們用語言的方式，自然語言方式跟他講說，如果這個人經過這個門，沒有戴著那個安全帽，馬上發出一個警報，或是把那個門給他關起來。